{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.2\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import pytesseract\n",
    "import numpy as np \n",
    "from imutils.object_detection import non_max_suppression\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Identify the text in the image (optical character recognition). \n",
    "### You can use any pretrained model or you can train your own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tesseract-OCR - need to be installed in your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract.exe' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating argument dictionary for the default arguments needed in the code. \n",
    "args = { \"min_confidence\":0.7, \"width\":320, \"height\":320}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give location of the image to be read.\n",
    "\n",
    "image = cv2.imread('test3.png')\n",
    "\n",
    "#Saving a original image and shape\n",
    "orig = image.copy()\n",
    "(origH, origW) = image.shape[:2]\n",
    "\n",
    "# set the new height and width to default 320 by using args #dictionary.  \n",
    "(newW, newH) = (args[\"width\"], args[\"height\"])\n",
    "\n",
    "#Calculate the ratio between original and new image for both height and weight. \n",
    "#This ratio will be used to translate bounding box location on the original image. \n",
    "rW = origW / float(newW)\n",
    "rH = origH / float(newH)\n",
    "\n",
    "# resize the original image to new dimensions\n",
    "image = cv2.resize(image, (newW, newH))\n",
    "(H, W) = image.shape[:2]\n",
    "\n",
    "# construct a blob from the image to forward pass it to EAST model\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),(123.68, 116.78, 103.94), swapRB=True, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained EAST model for text detection \n",
    "net = cv2.dnn.readNet('frozen_east_text_detection.pb')\n",
    "\n",
    "# We would like to get two outputs from the EAST model. \n",
    "#1. Probabilty scores for the region whether that contains text or not. \n",
    "#2. Geometry of the text -- Coordinates of the bounding box detecting a text\n",
    "# The following two layer need to pulled from EAST model for achieving this. \n",
    "layerNames = [\"feature_fusion/Conv_7/Sigmoid\",\"feature_fusion/concat_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward pass the blob from the image to get the desired output layers\n",
    "net.setInput(blob)\n",
    "(scores, geometry) = net.forward(layerNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Returns a bounding box and probability score if it is more than minimum confidence\n",
    "def predictions(prob_score, geo):\n",
    "    (numR, numC) = prob_score.shape[2:4]\n",
    "    boxes = []\n",
    "    confidence_val = []\n",
    "\n",
    "    # loop over rows\n",
    "    for y in range(0, numR):\n",
    "        scoresData = prob_score[0, 0, y]\n",
    "        x0 = geo[0, 0, y]\n",
    "        x1 = geo[0, 1, y]\n",
    "        x2 = geo[0, 2, y]\n",
    "        x3 = geo[0, 3, y]\n",
    "        anglesData = geo[0, 4, y]\n",
    "\n",
    "        # loop over the number of columns\n",
    "        for i in range(0, numC):\n",
    "            if scoresData[i] < args[\"min_confidence\"]:\n",
    "                continue\n",
    "\n",
    "            (offX, offY) = (i * 4.0, y * 4.0)\n",
    "\n",
    "            # extracting the rotation angle for the prediction and computing the sine and cosine\n",
    "            angle = anglesData[i]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "\n",
    "            # using the geo volume to get the dimensions of the bounding box\n",
    "            h = x0[i] + x2[i]\n",
    "            w = x1[i] + x3[i]\n",
    "\n",
    "            # compute start and end for the text pred bbox\n",
    "            endX = int(offX + (cos * x1[i]) + (sin * x2[i]))\n",
    "            endY = int(offY - (sin * x1[i]) + (cos * x2[i]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "\n",
    "            boxes.append((startX, startY, endX, endY))\n",
    "            confidence_val.append(scoresData[i])\n",
    "\n",
    "    # return bounding boxes and associated confidence_val\n",
    "    return (boxes, confidence_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find predictions and  apply non-maxima suppression\n",
    "(boxes, confidence_val) = predictions(scores, geometry)\n",
    "boxes = non_max_suppression(np.array(boxes), probs=confidence_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Text Detection and Recognition \n",
    "\n",
    "# initialize the list of results\n",
    "results = []\n",
    "\n",
    "# loop over the bounding boxes to find the coordinate of bounding boxes\n",
    "for (startX, startY, endX, endY) in boxes:\n",
    "    # scale the coordinates based on the respective ratios in order to reflect bounding box on the original image\n",
    "    startX = int(startX * rW)\n",
    "    startY = int(startY * rH)\n",
    "    endX = int(endX * rW)\n",
    "    endY = int(endY * rH)\n",
    "\n",
    "    #extract the region of interest\n",
    "    r = orig[startY:endY, startX:endX]\n",
    "\n",
    "    #configuration setting to convert image to string.  \n",
    "    configuration = (\"-l eng --oem 1 --psm 8\")\n",
    "    ##This will recognize the text from the image of bounding box\n",
    "    text = pytesseract.image_to_string(r, config=configuration)\n",
    "\n",
    "    # append bbox coordinate and associated text to the list of results \n",
    "    results.append(((startX, startY, endX, endY), text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deeo\n",
      "\n",
      "Machi\n",
      "\n",
      "Learninc\n",
      "\n",
      "ligence\n",
      "\n",
      "Artificial]\n",
      "\n",
      "~Cratictic\n",
      "\n",
      "ky\n",
      "\n",
      "Learnina\n",
      "\n",
      "-earning.\n",
      "\n",
      "&\n",
      "\n",
      "SY\n",
      "\n",
      "mi\n",
      "\n",
      "A\n",
      "\n",
      "Resized Dimensions :  (259, 938, 3)\n"
     ]
    }
   ],
   "source": [
    "#Display the image with bounding box and recognized text\n",
    "orig_image = orig.copy()\n",
    "\n",
    "# Moving over the results and display on the image\n",
    "for ((start_X, start_Y, end_X, end_Y), text) in results:\n",
    "    # display the text detected by Tesseract\n",
    "    print(\"{}\\n\".format(text))\n",
    "\n",
    "    # Displaying text\n",
    "    text = \"\".join([x if ord(x) < 128 else \"\" for x in text]).strip()\n",
    "    cv2.rectangle(orig_image, (start_X, start_Y), (end_X, end_Y),\n",
    "        (255, 0, 0), 2)\n",
    "    cv2.putText(orig_image, text, (start_X, start_Y - 30),\n",
    "       cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0, 255,0), 2)\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.imshow(orig_image)\n",
    "# plt.title('Output')\n",
    "# plt.show()\n",
    "\n",
    "scale_percent = 70 # percent of original size\n",
    "width = int(orig_image.shape[1] * scale_percent / 100)\n",
    "height = int(orig_image.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "\n",
    "resized = cv2.resize(orig_image, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "print('Resized Dimensions : ',resized.shape)\n",
    "\n",
    "\n",
    "cv2.imshow('Detected',resized) \n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
